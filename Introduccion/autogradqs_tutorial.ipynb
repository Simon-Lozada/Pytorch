{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferenciación automática con ``torch.autograd``\n",
    " =======================================\n",
    "\n",
    " Al entrenar redes neuronales, el algoritmo más utilizado es\n",
    " **propagación hacia atrás**.  En este algoritmo, los parámetros (pesos del modelo) son\n",
    " ajustado de acuerdo con el **gradiente** de la función de pérdida con respecto\n",
    " al parámetro dado.\n",
    "\n",
    " Para calcular esos gradientes, PyTorch tiene un motor de diferenciación incorporado\n",
    " llamado ``torch.autograd``.  Es compatible con el cálculo automático de pendiente para cualquier\n",
    " gráfico computacional.\n",
    "\n",
    " Considere la red neuronal de una capa más simple, con entrada ``x``,\n",
    " parámetros ``w`` y ``b``, y alguna función de pérdida.  Se puede definir en\n",
    " PyTorch de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensores, Funciones y Gráfico computacional\n",
    "------------------------------------------\n",
    "\n",
    "Este código define el siguiente **gráfico computacional**:\n",
    "\n",
    ".. figure:: /_static/img/basics/comp-graph.png\n",
    "   :alt:\n",
    "\n",
    "En esta red, ``w`` y ``b`` son **parámetros**, que necesitamos\n",
    "optimizar. Por lo tanto, necesitamos poder calcular los gradientes de pérdida\n",
    "función con respecto a esas variables. Para ello, establecemos\n",
    "la propiedad ``requires_grad`` de esos tensores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Nota</h4><p>Puede establecer el valor de ``requires_grad`` al crear un\n",
    "           tensor, o posterior usando el método ``x.requires_grad_(True)``.p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función que aplicamos a los tensores para construir un gráfico computacional es\n",
    "de hecho un objeto de la clase ``Function``. Este objeto sabe cómo\n",
    "calcular la función en la dirección *hacia adelante*, y también cómo calcular\n",
    "su derivada durante el paso de *propagación hacia atrás*. Una referencia a\n",
    "la función de propagación hacia atrás se almacena en la propiedad ``grad_fn`` de un\n",
    "tensor. Puede encontrar más información de ``Function`` `en el\n",
    "documentación <https://pytorch.org/docs/stable/autograd.html#function>`__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7fb334603a90>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fb334603910>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Gradients\n",
    "-------------------\n",
    "\n",
    "Para optimizar los pesos de los parámetros en la red neuronal, necesitamos\n",
    "calcular las derivadas de nuestra función de pérdida con respecto a los parámetros,\n",
    "es decir, necesitamos $\\frac{\\partial loss}{\\partial w}$ and\n",
    "$\\frac{\\partial pérdida}{\\partial b}$ bajo unos valores fijos de\n",
    "``x`` y ``y``. Para calcular esas derivadas, llamamos\n",
    "``loss.backward()``, y luego recuperar los valores de ``w.grad`` y\n",
    "``b.grad``:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2421, 0.2549, 0.1080],\n",
      "        [0.2421, 0.2549, 0.1080],\n",
      "        [0.2421, 0.2549, 0.1080],\n",
      "        [0.2421, 0.2549, 0.1080],\n",
      "        [0.2421, 0.2549, 0.1080]])\n",
      "tensor([0.2421, 0.2549, 0.1080])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Nota</h4><p>- Solo podemos obtener las propiedades ``grad`` para la hoja\n",
    "     nodos del grafo computacional, que tienen la propiedad ``requires_grad``\n",
    "     establecido en ``True``. Para todos los demás nodos en nuestro gráfico, los gradientes no serán\n",
    "     disponible.\n",
    "    - Solo podemos realizar cálculos de gradiente usando\n",
    "    ``backward`` una vez en un gráfico dado, por motivos de rendimiento. si necesitamos\n",
    "     hacer varios``backward`` llamadas en el mismo gráfico, tenemos que pasar\n",
    "     ``retain_graph=True`` al llamar ``backward``.</p></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deshabilitar el seguimiento de degradado\n",
    "---------------------------\n",
    "\n",
    "Por defecto, todos los tensores con ``requires_grad=True`` siguen su\n",
    "historial computacional y cálculo de gradiente de soporte. Sin embargo, hay\n",
    "hay algunos casos en los que no necesitamos hacer eso, por ejemplo, cuando tenemos\n",
    "entrenamos el modelo y solo queremos aplicarlo a algunos datos de entrada, es decir,\n",
    "solo quiere hacer cálculos *hacia adelante* a través de la red. Nosotros podemos parar\n",
    "seguimiento de cálculos rodeando nuestro código de cálculo con\n",
    "Bloque ``torch.no_grad()``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de lograr el mismo resultado es usar el método ``detach()``\n",
    " en el tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay razones por las que es posible que desee deshabilitar el seguimiento de gradiente:\n",
    "   - Para marcar algunos parámetros en su red neuronal como **parámetros congelados**.  Esto es\n",
    "     un escenario muy común para\n",
    "     `ajuste fino de una red preentrenada <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>`__\n",
    "   - Para **acelerar los cómputos** cuando solo está haciendo pases hacia adelante, porque los cómputos en tensores que sí lo hacen\n",
    "     no rastrear gradientes sería más eficiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre gráficos computacionales\n",
    " ----------------------------\n",
    " Conceptualmente, autograd mantiene un registro de datos (tensores) y todos los ejecutados\n",
    " operaciones (junto con los nuevos tensores resultantes) en un acíclico dirigido\n",
    " gráfico (DAG) que consta de\n",
    " `Función <https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function>`__\n",
    " objetos.  En este DAG, las hojas son los tensores de entrada, las raíces son la salida\n",
    " tensores.  Al trazar este gráfico desde las raíces hasta las hojas, puedes\n",
    " calcular automáticamente los gradientes utilizando la regla de la cadena.\n",
    "\n",
    " En un pase hacia adelante, autograd hace dos cosas simultáneamente:\n",
    "\n",
    " - ejecutar la operación solicitada para calcular un tensor resultante\n",
    " - mantener la *función de gradiente* de la operación en el DAG.\n",
    "\n",
    " El pase hacia atrás comienza cuando se llama ``.backward()`` en el DAG\n",
    " raíz.  ``autograd`` entonces:\n",
    "\n",
    " - calcula los gradientes de cada ``.grad_fn``,\n",
    " - los acumula en el atributo ``.grad`` del tensor respectivo\n",
    " - utilizando la regla de la cadena, se propaga hasta los tensores de hoja.\n",
    "\n",
    " <div class=\"alert alert-info\"><h4>Nota</h4><p>**Los DAG son dinámicos en PyTorch**\n",
    "   Una cosa importante a tener en cuenta es que el gráfico se recrea desde cero;  después de cada\n",
    "   llamada ``.backward()``, autograd comienza a llenar un nuevo gráfico.  Esto es\n",
    "   exactamente lo que le permite usar declaraciones de flujo de control en su modelo;\n",
    "   puede cambiar la forma, el tamaño y las operaciones en cada iteración si\n",
    "   necesario.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura opcional: gradientes tensoriales y productos jacobianos\n",
    " ---------------------------------------------\n",
    "\n",
    " En muchos casos, tenemos una función de pérdida escalar y necesitamos calcular\n",
    " el gradiente con respecto a algunos parámetros.  Sin embargo, hay casos\n",
    " cuando la función de salida es un tensor arbitrario.  En este caso, PyTorch\n",
    " le permite calcular el llamado **producto jacobiano**, y no el real\n",
    " degradado.\n",
    "Para una función vectorial $\\vec{y}=f(\\vec{x})$, where\n",
    "$\\vec{x}=\\langle x_1,\\dots,x_n\\rangle$ y\n",
    "$\\vec{y}=\\langle y_1,\\dots,y_m\\rangle$,un gradiente de\n",
    "$\\vec{y}$ con respecto a $\\vec{x}$ es dado por **Matriz Jacobina**:\n",
    "\n",
    "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
    "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "      \\vdots & \\ddots & \\vdots\\\\\n",
    "      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "      \\end{array}\\right)\\end{align}\n",
    "\n",
    "En lugar de calcular la propia matriz jacobiana, PyTorch le permite\n",
    "computar **Producto jacobiano** $v^T\\cdot J$ for a given input vector\n",
    "$v=(v_1 \\dots v_m)$. Esto se logra llamando ``backward()`` con\n",
    "$v$ como argumento.El tamaño de $v$ debe ser el mismo que\n",
    "el tamaño del tensor original, con respecto al cual queremos\n",
    "calcular el producto:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"First call\\n{inp.grad}\")\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que cuando llamamos ``.backward()`` por segunda vez con el mismo\n",
    " argumento, el valor del gradiente es diferente.  Esto sucede porque\n",
    " al hacer la propagación ``.backward()``, PyTorch **acumula el\n",
    " gradientes**, es decir, el valor de los gradientes calculados se suma al\n",
    " Propiedad ``grad`` de todos los nodos hoja del gráfico computacional.  Si tu quieres\n",
    " para calcular los gradientes adecuados, debe poner a cero el ``grad``\n",
    " propiedad antes.  En el entrenamiento de la vida real, un *optimizador* nos ayuda a hacer\n",
    " este.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Nota</h4><p>Previamente estábamos llamando a la función ``backward()`` sin\n",
    "           parámetros  Esto es esencialmente equivalente a llamar\n",
    "          ``backward(torch.tensor(1.0))``, que es una forma útil de calcular el\n",
    "           gradientes en el caso de una función de valor escalar, como la pérdida durante\n",
    "           entrenamiento de redes neuronales.</p></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 1.200, loos = 30.00000000\n",
      "epoch 3: w = 1.872, loos = 0.76800019\n",
      "epoch 5: w = 1.980, loos = 0.01966083\n",
      "epoch 7: w = 1.997, loos = 0.00050331\n",
      "epoch 9: w = 1.999, loos = 0.00001288\n",
      "epoch 11: w = 2.000, loos = 0.00000033\n",
      "epoch 13: w = 2.000, loos = 0.00000001\n",
      "epoch 15: w = 2.000, loos = 0.00000000\n",
      "epoch 17: w = 2.000, loos = 0.00000000\n",
      "epoch 19: w = 2.000, loos = 0.00000000\n",
      "Prediction after trainig: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = w * x\n",
    "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype = np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, y_predicted - y).mean()\n",
    "\n",
    "# Trainnig\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # grandients\n",
    "    dw = gradient(X,Y, y_pred)\n",
    "    \n",
    "    #update the weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch + 1}: w = {w:.3f}, loos = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after trainig: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loos = 30.00000000\n",
      "epoch 3: w = 0.772, loos = 15.66018772\n",
      "epoch 5: w = 1.113, loos = 8.17471695\n",
      "epoch 7: w = 1.359, loos = 4.26725292\n",
      "epoch 9: w = 1.537, loos = 2.22753215\n",
      "epoch 11: w = 1.665, loos = 1.16278565\n",
      "epoch 13: w = 1.758, loos = 0.60698116\n",
      "epoch 15: w = 1.825, loos = 0.31684780\n",
      "epoch 17: w = 1.874, loos = 0.16539653\n",
      "epoch 19: w = 1.909, loos = 0.08633806\n",
      "Prediction after trainig: f(5) = 9.612\n"
     ]
    }
   ],
   "source": [
    "## ACTULIZANDO\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = w * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "# Trainnig\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predicción = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # pérdida\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # grandients = backward() #Bueno no exatamente en parte por eso no se tienen los mismos ressultdos\n",
    "    l.backward()\n",
    "    \n",
    "    #Actulizar los pesos\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        \n",
    "    # Poner en cero los gradientes\n",
    "    w.grad.zero_()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch + 1}: w = {w:.3f}, loos = {l:.8f}\")\n",
    "        \n",
    "print(f\"Prediction after trainig: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias A:\n",
    "----------------\n",
    "Documentacion oficial de pytorch: https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
    "\n",
    "Traducido por: Mi :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
