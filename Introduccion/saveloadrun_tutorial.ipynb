{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar y cargar el modelo\n",
    " ============================\n",
    "\n",
    " En esta sección, veremos cómo conservar el estado del modelo guardando, cargando y ejecutando predicciones del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar y cargar pesos de modelo\n",
    " --------------------------------\n",
    " Los modelos PyTorch almacenan los parámetros aprendidos en un\n",
    " diccionario de estado, llamado ``state_dict``.  Estos pueden persistir a través de ``torch.save``\n",
    " método:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar los pesos del modelo, primero debe crear una instancia del mismo modelo y luego cargar los parámetros.\n",
    " utilizando el método ``load_state_dict()``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16() # no especificamos pretrained=True, es decir, no cargamos pesos predeterminados\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar y cargar modelos con formas\n",
    " -------------------------------------\n",
    " Al cargar los pesos del modelo, primero necesitábamos crear una instancia de la clase del modelo, porque la clase\n",
    " define la estructura de una red.  Podríamos querer guardar la estructura de esta clase junto con\n",
    " el modelo, en cuyo caso podemos pasar ``model`` (y no ``model.state_dict()``) a la función de guardado:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces podemos cargar el modelo así:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Nota</h4><p>Este enfoque utiliza Python`pickle <https://docs.python.org/3/library/pickle.html>`_ módulo al serializar el modelo, por lo tanto, se basa en la definición de clase real para estar disponible al cargar el modelo.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar y cargar Puntos del Entrenamiento\n",
    " -------------------------------------\n",
    " \n",
    " Imaginemos que tenmos el siguiente modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardamos los parametros bajo los cuales queremos hacer nuestro punto de control**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "checkpoint = {\n",
    "\"epoch\": 90,\n",
    "\"model_state\": model.state_dict(),\n",
    "\"optim_state\": optimizer.state_dict()\n",
    "}\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salvamos nuestro modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"checkpoint.pth\"\n",
    "#torch.save(Parametros de guardado, Nombre del archivo)\n",
    "torch.save(checkpoint, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supongamos que nuestro modelo queda asi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_input_features=6)\n",
    "optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Asi cargariamos nuestro modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar modelo\n",
    "checkpoint = torch.load(FILE)\n",
    "\n",
    "#Cargar el estado del modelo\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "#Cargar el optimizador del modelo\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "\n",
    "#Cargar la epoca del modelo\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "#Entrenamos nuestro modelo\n",
    "# model.train()\n",
    "# - or -\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
