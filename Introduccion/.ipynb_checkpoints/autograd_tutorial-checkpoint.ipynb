{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1655758613288,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "-3zamaHG8PtC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OeYTyHq8PtG"
   },
   "source": [
    "\n",
    "Una suave introducción a ``torch.autograd``\n",
    "---------------------------------\n",
    "\n",
    "``torch.autograd`` es el motor de diferenciación automática de PyTorch que impulsa\n",
    "entrenamiento de redes neuronales. En esta sección, obtendrá una descripción\n",
    "comprensión de cómo el autogrado ayuda a entrenar una red neuronal.\n",
    "\n",
    "Background\n",
    "~~~~~~~~~~\n",
    "Las redes neuronales (NN) son una colección de funciones anidadas que se ejecutan en algunos datos de entrada. Estas funciones están definidas por parámetros (que consisten en pesos y sesgos), que en PyTorch se almacenan en tensores.\n",
    "\n",
    "El entrenamiento de un NN ocurre en dos pasos:\n",
    "\n",
    "**Forward Propagation(Propagación hacia adelante)**: en el apoyo hacia adelante, el NN hace su mejor \n",
    "conjetura sobre la salida correcta. Ejecuta los datos de entrada a través de \n",
    "cada una de sus funciones para realizar esta conjetura.\n",
    "\n",
    "**Backward Propagation(Propagación hacia atrás)**:  : en backprop, el NN ajusta sus parámetros\n",
    "proporcionalmente al error en su conjetura. Para ello, realiza un recorrido \n",
    "hacia atrás desde la salida, recopila las derivadas del error con respecto a \n",
    "los parámetros de las funciones ( gradientes ) y optimiza los parámetros \n",
    "mediante el descenso de gradiente. Para obtener un tutorial más detallado de \n",
    "backprop, vea este video de 3Blue1Brown .<https://www.youtube.com/watch?v=tIeHLnjs5U8>`__.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Uso en PyTorch\n",
    "~~~~~~~~~~~\n",
    "Echemos un vistazo a un solo paso de entrenamiento. \n",
    "Para este ejemplo, cargamos un modelo resnet18 previamente entrenado de \n",
    "``torchvision``.\n",
    "Creamos un tensor de datos aleatorios para representar una sola imagen con 3\n",
    "canales, y alto y ancho de 64, y su correspondiente ``label``inicializado a\n",
    "algunos valores aleatorios.\n",
    "\n",
    "Importante\n",
    "~~~~~~~~~~~\n",
    "Este tutorial funciona solo en CPU y no funcionará en GPU (incluso si el tensor se mueve a CUDA).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "30f8a2e0c92c418f9380888ac304c1f2",
      "582f8cb01fd442d299826c980672efec",
      "55dc2127b9504b979e118e778e26e9ce",
      "acc7bc372a80409bbf2bd78d8e5e7e26",
      "128df87c426e4be99c15917d7484bdef",
      "19a28cb5d96e46f89f268306708d1525",
      "9ab35e57efeb483881f00c7af2a64582",
      "42a2f60f65054d2c9dfd835a7e63297a",
      "f12a5419dc80403a9fb12c617c13ae61",
      "091905b0e5904148a44caa88dd3f5e94",
      "77479e8b13594298b856a61a846e7bd6"
     ]
    },
    "executionInfo": {
     "elapsed": 8373,
     "status": "ok",
     "timestamp": 1655758621653,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "zl9huY018PtK",
    "outputId": "3512f34e-2ff3-49d1-b641-a95a4d274409"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/monky/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b2e9890f1948e395d510556472a972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AkgtGFW8PtL"
   },
   "source": [
    "*A continuación*, ejecutamos los datos de entrada a través del modelo a través de cada una de sus capas para hacer una predicción.\n",
    "Este es el **pase hacia adelante**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1655758622143,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "YeiPE5WE8PtM"
   },
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvhLE2jR8PtM"
   },
   "source": [
    "Usamos la predicción del modelo y la etiqueta correspondiente para calcular el error (``loss``).\n",
    "El siguiente paso es propagar este error a través de la red.\n",
    "\n",
    "La propagación hacia atrás se inicia cuando llamamos a ``.backward()`` en el tensor de error.\n",
    "\n",
    "Luego, Autograd calcula y almacena los gradientes para cada parámetro del modelo en el atributo ``.grad`` del parámetro.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1655758622145,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "isgQXfxb8PtN"
   },
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufKXu2Ht8PtO"
   },
   "source": [
    "A continuación, cargamos un optimizador, en este caso SGD con una tasa de aprendizaje de 0.01 y [momentum](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d) de 0,9.\n",
    "Registramos todos los parámetros del modelo en el optimizador.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1655758622149,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "q_LIiswM8PtO"
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQETdfxp8PtP"
   },
   "source": [
    "Finalmente, llamamos ``.step()``a iniciar el descenso de gradiente. El optimizador ajusta cada parámetro por su gradiente almacenado en ``.grad``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1655758622150,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "OwUsU1e_8PtQ"
   },
   "outputs": [],
   "source": [
    "optim.step() #desenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wg80CUz38PtQ"
   },
   "source": [
    "En este punto, tienes todo lo que necesitas para entrenar tu red neuronal. Las siguientes secciones detallan el funcionamiento de autograduación; siéntase libre de omitirlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzJNy2EF8PtQ"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOiJP2j78PtR"
   },
   "source": [
    "Diferenciación en Autograd\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Echemos un vistazo a cómo``autograd`` recopila los degradados. Creamos dos tensores ``a`` y ``b`` con\n",
    "``requires_grad=True``. Esto indica ``autograd`` que se debe realizar un seguimiento de cada operación en ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1655758622151,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "AcMThzXq8PtR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tvgX7DY8PtS"
   },
   "source": [
    "Creamos otro tensor a ``Q`` partir de ``a`` y ``b``.\n",
    "\n",
    "\\begin{align}Q = 3a^3 - b^2\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1655758622152,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "rN8P9WTu8PtT"
   },
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnVgRviy8PtT"
   },
   "source": [
    "Supongamos que ``a`` y ``b``son parámetros de un NN, y``Q``\n",
    "es el error. En el entrenamiento NN, queremos gradientes de los parámetros wrt de error, es decir\n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n",
    "\n",
    "\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n",
    "\n",
    "\n",
    "Cuando llamamos ``.backward()`` a ``Q``, autograd calcula estos gradientes y los almacena en los respectivos tensores ``.grad`` atributo.\n",
    "\n",
    "Necesitamos pasar explícitamente un ``gradient`` argumento ``Q.backward()`` porque es un vector\n",
    "``gradient`` es un tensor de la misma forma que ``Q``,y representa el\n",
    "degradado Q w.r.t. de sí mismo, es decir\n",
    "\n",
    "\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n",
    "\n",
    "De manera equivalente, también podemos agregar Q en un escalar y llamar hacia atrás implícitamente, como ``Q.sum().backward()``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1655758622153,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "uWXREyA08PtT"
   },
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh6ntOZu8PtT"
   },
   "source": [
    "Los degradados ahora se depositan en ``a.grad`` y ``b.grad``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1655758622154,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "IXZqAuWM8PtU",
    "outputId": "b08d2c66-cc46-484c-eb9a-fb1e59ecd9a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "# comprobar si los gradientes recopilados son correctos\n",
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CzuDYzK8PtU"
   },
   "source": [
    "Lectura opcional: cálculo vectorial usando ``autograd``\n",
    "\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Matemáticamente, si tienes una función con valor vectorial\n",
    "$\\vec{y}=f(\\vec{x})$, luego el gradiente de $\\vec{y}$ con respecto a\n",
    " $\\vec{x}$ es una matriz jacobiana $J$:\n",
    "\n",
    "\\begin{align}J\n",
    "     =\n",
    "      \\left(\\begin{array}{cc}\n",
    "      \\frac{\\partial \\bf{y}}{\\partial x_{1}} &\n",
    "      ... &\n",
    "      \\frac{\\partial \\bf{y}}{\\partial x_{n}}\n",
    "      \\end{array}\\right)\n",
    "     =\n",
    "     \\left(\\begin{array}{ccc}\n",
    "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "      \\vdots & \\ddots & \\vdots\\\\\n",
    "      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "      \\end{array}\\right)\\end{align}\n",
    "\n",
    "En terminos generales, ``torch.autograd`` es un prodructo  vectorial-jacobiano. Es decir dado cualquier vector $\\vec{v}$, calcula el producto\n",
    "$J^{T}\\cdot \\vec{v}$\n",
    "\n",
    "Si $\\vec{v}$ pasa a ser el gradiente de funcion escalar $l=g\\left(\\vec{y}\\right)$:\n",
    "\n",
    "\\begin{align}\\vec{v}\n",
    "   =\n",
    "   \\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}\\end{align}\n",
    "\n",
    "luego, por regla de cadena, el producto vectorial-jacobiano seria el gradiente de $l$ con respecto a $\\vec{x}$:\n",
    "\n",
    "\\begin{align}J^{T}\\cdot \\vec{v}=\\left(\\begin{array}{ccc}\n",
    "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
    "      \\vdots & \\ddots & \\vdots\\\\\n",
    "      \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "      \\end{array}\\right)\\left(\\begin{array}{c}\n",
    "      \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
    "      \\vdots\\\\\n",
    "      \\frac{\\partial l}{\\partial y_{m}}\n",
    "      \\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "      \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
    "      \\vdots\\\\\n",
    "      \\frac{\\partial l}{\\partial x_{n}}\n",
    "      \\end{array}\\right)\\end{align}\n",
    "\n",
    "Esta característica del producto vector-jacobiano es lo que usamos en el ejemplo anterior;\n",
    "``external_grad`` representa $\\vec{v}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "#ejemplo:\n",
    "\n",
    "weights = torch.ones(4, requires_grad = True)\n",
    "\n",
    "for epocg in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    #podemos reiniciar los pesos con\n",
    "    #weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbqCp1OL8PtU"
   },
   "source": [
    "Gráfico computacional\n",
    "~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Conceptualmente, autograd mantiene un registro de datos (tensores) y todas las\n",
    "operaciones ejecutadas (junto con los nuevos tensores resultantes) en un\n",
    "gráfico acíclico dirigido (DAG) que consta de objetos de\n",
    "`Función <https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function>`__\n",
    "En este DAG, las hojas son los tensores de entrada, las raíces son los tensores\n",
    "de salida. Al trazar este gráfico desde las raíces hasta las hojas, puede \n",
    "calcular automáticamente los gradientes usando la regla de la cadena.\n",
    "\n",
    "En un pase adelantado, autograd hace dos cosas simultáneamente:\n",
    "\n",
    "- ejecutar la operación solicitada para calcular un tensor resultante, y\n",
    "- mantener la función de gradiente de la operación en el DAG.\n",
    "\n",
    "El pase hacia atrás comienza cuando ``.backward()``se llama en la raíz del DAG. ``autograd`` Entoneces:\n",
    "\n",
    "- calcula los gradientes de cada uno``.grad_fn``,\n",
    "- los acumula en el ``.grad``atributo del tensor respectivo , y\n",
    "- utilizando la regla de la cadena, se propaga hasta los tensores foliares.\n",
    "\n",
    "A continuación se muestra una representación visual del DAG en nuestro ejemplo.\n",
    "En el gráfico, las flechas están en la dirección del pase hacia adelante. Los \n",
    "nodos representan las funciones hacia atrás de cada operación en el pase hacia \n",
    "adelante. Los nodos de hojas en azul representan nuestros tensores de hojas \n",
    "``a`` and ``b``.\n",
    "\n",
    ".. Figura: /_static/img/dag_autograd.png\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>NOTA</h4><p>**Los DAG son dinámicos en PyTorch.**\n",
    "Una cosa importante a tener en cuenta es que el gráfico se recrea desde cero; después de cada \n",
    "``.backward()``llamada, autograd comienza a completar un nuevo gráfico. Esto es\n",
    "exactamente lo que le permite utilizar declaraciones de flujo de control en su\n",
    "modelo; puede cambiar la forma, el tamaño y las operaciones en cada iteración\n",
    "si es necesario.</p></div>\n",
    "\n",
    "Exclusión del DAG\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "``torch.autograd``rastrea las operaciones en todos los tensores que tienen su \n",
    "``requires_grad`` bandera establecida en ``True``.\n",
    "Para tensores que no requieren gradientes, configurar este atributo para  ``False`` excluirlo del DAG\n",
    "de cálculo de gradiente.\n",
    "El tensor de salida de una operación requerirá gradientes incluso si solo tiene un tensor de entrada ``requires_grad=True``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1655758622155,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "Y6WSo3xF8PtV",
    "outputId": "3b637211-29e4-4ef2-db57-a0bd5105d1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"¿`a` requiere gradientes? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"¿`b` requiere gradientes?: {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRrCxTLI8PtV"
   },
   "source": [
    "En una NN, los parámetros que no calculan gradientes generalmente se denominan **parámetros congelados**.\n",
    "Es útil \"congelar\" parte de su modelo si sabe de antemano que no necesitará los \n",
    "gradientes de esos parámetros (esto ofrece algunos beneficios de rendimiento al \n",
    "reducir los cálculos de autogrado).\n",
    "\n",
    "Otro caso de uso común donde la exclusión del DAG es importante es para\n",
    "`ajustar una red previamente capacitada <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>`__\n",
    "\n",
    "En el ajuste fino, congelamos la mayor parte del modelo y, por lo general, solo \n",
    "modificamos las capas del clasificador para hacer predicciones en nuevas \n",
    "etiquetas. Veamos un pequeño ejemplo para demostrarlo. Como antes, cargamos un \n",
    "modelo resnet18 previamente entrenado y congelamos todos los parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1655758622448,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "W2BWoR6X8PtW"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT1MtXU68PtW"
   },
   "source": [
    "Digamos que queremos ajustar el modelo en un nuevo conjunto de datos con 10 etiquetas. En resnet, el clasificador es la última capa lineal ``model.fc``.\n",
    "Simplemente podemos reemplazarlo con una nueva capa lineal (descongelada por defecto) que actúa como nuestro clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1655758622450,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "Cq8HveDY8PtW"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4TEqouf8PtW"
   },
   "source": [
    "Ahora todos los parámetros del modelo, excepto los parámetros de ``model.fc``, estan congeladas.\n",
    "Los únicos parámetros que calculan los gradientes son los pesos y el sesgo de ``model.fc``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1655758622451,
     "user": {
      "displayName": "Simon Lozada",
      "userId": "15782723165928499535"
     },
     "user_tz": 180
    },
    "id": "17IZD_848PtW"
   },
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oADrYvHC8PtX"
   },
   "source": [
    "Observe que, aunque registramos todos los parámetros en el optimizador, los únicos parámetros que calculan gradientes (y, por lo tanto, se actualizan en el descenso de gradientes)\n",
    "son los pesos y el sesgo del clasificador.\n",
    "\n",
    "La misma funcionalidad de exclusión está disponible como administrador de contexto en\n",
    "`torch.no_grad() <https://pytorch.org/docs/stable/generated/torch.no_grad.html>`__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwFMmcsO8PtX"
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuAT6EoP8PtX"
   },
   "source": [
    "Lecturas adicionales:\n",
    "~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "-  `Operaciones in situ y autogrado multiproceso <https://pytorch.org/docs/stable/notes/autograd.html>`__\n",
    "-  `Implementación de ejemplo de autodiff en modo inverso <https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC>`__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias A:\n",
    "----------------\n",
    "Documentacion oficial de pytorch:\n",
    "    \n",
    "Traducido por: Mi :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de autograd_tutorial.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/009cea8b0f40dfcb55e3280f73b06cc2/autograd_tutorial.ipynb",
     "timestamp": 1640978518075
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091905b0e5904148a44caa88dd3f5e94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "128df87c426e4be99c15917d7484bdef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19a28cb5d96e46f89f268306708d1525": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30f8a2e0c92c418f9380888ac304c1f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_582f8cb01fd442d299826c980672efec",
       "IPY_MODEL_55dc2127b9504b979e118e778e26e9ce",
       "IPY_MODEL_acc7bc372a80409bbf2bd78d8e5e7e26"
      ],
      "layout": "IPY_MODEL_128df87c426e4be99c15917d7484bdef"
     }
    },
    "42a2f60f65054d2c9dfd835a7e63297a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55dc2127b9504b979e118e778e26e9ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42a2f60f65054d2c9dfd835a7e63297a",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f12a5419dc80403a9fb12c617c13ae61",
      "value": 46830571
     }
    },
    "582f8cb01fd442d299826c980672efec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19a28cb5d96e46f89f268306708d1525",
      "placeholder": "​",
      "style": "IPY_MODEL_9ab35e57efeb483881f00c7af2a64582",
      "value": "100%"
     }
    },
    "77479e8b13594298b856a61a846e7bd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ab35e57efeb483881f00c7af2a64582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acc7bc372a80409bbf2bd78d8e5e7e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_091905b0e5904148a44caa88dd3f5e94",
      "placeholder": "​",
      "style": "IPY_MODEL_77479e8b13594298b856a61a846e7bd6",
      "value": " 44.7M/44.7M [00:01&lt;00:00, 56.3MB/s]"
     }
    },
    "f12a5419dc80403a9fb12c617c13ae61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
