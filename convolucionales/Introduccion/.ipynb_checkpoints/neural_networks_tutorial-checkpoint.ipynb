{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab848c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f50df5",
   "metadata": {},
   "source": [
    "Este es el modelo que entrenaremos.  Si le parece familiar, es porque es una variante de LeNet, adaptada para imágenes de 3 colores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef06a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 canal de imagen de entrada, 6 canales de salida, convolución cuadrada de 5x5\n",
    "        # núcleo\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # una operación afín: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 de la dimensión de la imagen\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Agrupación máxima sobre una ventana (2, 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # Si el tamaño es un cuadrado, puede especificar con un solo número\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # Aplanar todas las dimensiones excepto la dimensión del lote\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a477b26",
   "metadata": {},
   "source": [
    "Solo tienes que definir la función **forward**, y la funcion **backward** (donde se calculan los gradientes) se define automáticamente para usted usando **autograd.** Puede usar cualquiera de las operaciones de Tensor en la funcion **forward**.\n",
    "\n",
    "Los parámetros aprendibles de un modelo son devueltos por net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0d0980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # peso de conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b6cac",
   "metadata": {},
   "source": [
    "Probemos una entrada aleatoria de 32x32.  Nota: el tamaño de entrada esperado de esta red (LeNet) es 32x32.  Para usar esta red en el conjunto de datos MNIST, cambie el tamaño de las imágenes del conjunto de datos a 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbedfa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1584, -0.1281, -0.0253,  0.0690,  0.0573,  0.1196,  0.0716,  0.0188,\n",
      "          0.1474,  0.0272]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfa5c1",
   "metadata": {},
   "source": [
    "creamos una entrada ficticia que representa una imagen de 32x32 con 1\n",
    " canal de color  Normalmente, cargaría un mosaico de imagen y lo convertiría a\n",
    " un tensor de esta forma.\n",
    "\n",
    " Es posible que haya notado una dimensión adicional en nuestro tensor: el * lote\n",
    " dimensión.* Los modelos de PyTorch asumen que están trabajando en *lotes* de datos\n",
    " - por ejemplo, un lote de 16 de nuestros mosaicos de imágenes tendría la forma\n",
    " ``(16, 1, 32, 32)``.  Como solo estamos usando una imagen, creamos un lote\n",
    " de 1 con forma ``(1, 1, 32, 32)``.\n",
    "\n",
    " Le pedimos al modelo una inferencia llamándolo como una función:\n",
    " ``red(entrada)``.  La salida de esta llamada representa el modelo\n",
    " confianza de que la entrada representa un dígito particular.  (Desde esto\n",
    " instancia del modelo aún no ha aprendido nada, no deberíamos esperar\n",
    " para ver cualquier señal en la salida.) Mirando la forma de ``salida``, podemos\n",
    " puede ver que también tiene una dimensión de lote, cuyo tamaño debe\n",
    " siempre coincida con la dimensión del lote de entrada.  Si hubiésemos pasado en una entrada\n",
    " lote de 16 instancias, ``salida`` tendría una forma de ``(16, 10)``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d535f",
   "metadata": {},
   "source": [
    "Cero los buffers de gradiente de todos los parámetros y backprops con random gradientes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1129007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f5c7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Nota</h4><p>``torch.nn`` solo admite mini lotes.  Todo ``torch.nn``\n",
    "     El paquete solo admite entradas que son un mini lote de muestras, y no\n",
    "     una sola muestra\n",
    "\n",
    "\n",
    "    For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
    "    ``nSamples x nChannels x Height x Width``.\n",
    "\n",
    "    If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
    "    a fake batch dimension.</p></div>\n",
    "\n",
    "Antes de continuar, recapitulemos todas las clases que has visto hasta ahora.\n",
    "\n",
    "**Recap:**\n",
    "  -  ``torch.Tensor`` - UN *matriz multidimensional* compatible con autograd\n",
    "     operaciones como ``backward()``. Tambine *mantiene el gradiente* w.r.t. el\n",
    "     tensor.\n",
    "  -  ``nn.Module`` - Módulo de red neuronal.  * Manera conveniente de\n",
    "      encapsulando parámetros*, con asistentes para moverlos a la GPU,\n",
    "      exportar, cargar, etc.\n",
    "  -  ``nn.Parameter`` - Una especie de Tensor, que es *automáticamente\n",
    "      registrado como parámetro cuando se asigna como atributo a un*\n",
    "     ``Module``.\n",
    "  -  ``autograd.Function``- Implementa *definiciones hacia adelante y hacia atrás\n",
    "      de una operación de autograduación*. Cada ``Tensor`` la operación crea en\n",
    "      menos un solo nodo ``Función`` que se conecta a las funciones que\n",
    "      creó un ``Tensor`` y *codifica su historial*.\n",
    "\n",
    "**En este punto, cubrimos:**\n",
    "   - Definición de una red neuronal\n",
    "   - Procesamiento de entradas y llamadas hacia atrás.\n",
    "\n",
    "**Aún quedan:**\n",
    "   - Cálculo de la pérdida\n",
    "   - Actualización de los pesos de la red.\n",
    "\n",
    "Función de pérdida\n",
    "-------------\n",
    "Una función de pérdida toma el par de entradas (salida, objetivo) y calcula una\n",
    "valor que estima qué tan lejos está la salida del objetivo.\n",
    "\n",
    "Hay varios diferentes\n",
    "`funcion loss <https://pytorch.org/docs/nn.html#loss-functions>`_ bajo el\n",
    "nn paquete\n",
    "Una pérdida simple es: ``nn.MSELoss`` que calcula el error cuadrático medio\n",
    "entre la salida y el destino.\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a0750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0299, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)   # un objetivo ficticio, por ejemplo\n",
    "target = target.view(1, -1)# haz que tenga la misma forma que la salida\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fa7af",
   "metadata": {},
   "source": [
    "**Ahora**, si sigues ``loss`` en dirección hacia atrás, usando su\n",
    " atributo ``.grad_fn``, verá un gráfico de cálculos que parece\n",
    " como esto:\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> flatten -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "Entonces, cuando llamamos a ``loss.backward()``, todo el gráfico se diferencia\n",
    " escriba los parámetros de la red neuronal y todos los tensores en el gráfico que tienen\n",
    " ``requires_grad=True`` tendrá su Tensor ``.grad`` acumulado con el\n",
    " degradado.\n",
    "\n",
    " A modo de ilustración, sigamos unos pasos hacia atrás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96aec047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x7fe76416e5b0>\n",
      "<AddmmBackward0 object at 0x7fe76416e850>\n",
      "<AccumulateGrad object at 0x7fe76416e5b0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80a0c2",
   "metadata": {},
   "source": [
    "backprop\n",
    " --------\n",
    " Para retropropagar el error todo lo que tenemos que hacer es ``loss.backward()``.\n",
    " Sin embargo, debe borrar los gradientes existentes, de lo contrario, los gradientes serán\n",
    " acumulado a los gradientes existentes.\n",
    "\n",
    "\n",
    " Ahora llamaremos a ``loss.backward()``, y echaremos un vistazo al sesgo de conv1\n",
    " gradientes antes y después del retroceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a086a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad antes de backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad después de backward\n",
      "tensor([-0.0196,  0.0107,  0.0166, -0.0220,  0.0309,  0.0162])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # pone a cero los búferes de gradiente de todos los parámetros\n",
    "\n",
    "print('conv1.bias.grad antes de backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad después de backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e0b14",
   "metadata": {},
   "source": [
    "Ahora, hemos visto cómo usar las funciones de pérdida.\n",
    "\n",
    " **Leer más tarde:**\n",
    "\n",
    "   El paquete de red neuronal contiene varios módulos y funciones de pérdida\n",
    "   que forman los componentes básicos de las redes neuronales profundas.  Una lista completa con\n",
    "   la documentación está `aquí <https://pytorch.org/docs/nn>`_.\n",
    "\n",
    " **Lo único que queda por aprender es:**\n",
    "\n",
    " …implementa todos estos métodos.  Usarlo es muy simple:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583310c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# crea tu optimizador\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# en tu ciclo de entrenamiento:\n",
    "optimizer.zero_grad()   # poner a cero los búferes de gradiente\n",
    "\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()       # Actualizamos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c165de",
   "metadata": {},
   "source": [
    ".. Note::\n",
    "\n",
    "       Observe cómo los búferes de gradiente tenían que establecerse manualmente en cero usando\n",
    "       ``optimizador.zero_grad()``.  Esto se debe a que los gradientes se acumulan\n",
    "       como se explica en la sección `Backprop`_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f096f58",
   "metadata": {},
   "source": [
    "Gracias A:\n",
    "----------------\n",
    "Documentacion oficial de pytorch: https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "\n",
    "Traducido por: Mi :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f6b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
