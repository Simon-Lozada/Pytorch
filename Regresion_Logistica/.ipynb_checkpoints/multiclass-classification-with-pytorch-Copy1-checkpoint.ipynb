{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "e26b283a2d4bd99275cbe65cb5bbccf4b4fc7b7b"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a78d764f01d101a3ffd32325b5e1b30524d4760a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb4980573f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55fec0391594c4bda681436ea426841c59ec4227"
   },
   "source": [
    "# Load Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "02166de86c25371276dd58add6eeddb4037da6af"
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a05ea99716319490b7ceca4a6c8efeb99f2d006"
   },
   "source": [
    "Use train_test_split to split data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "83485b13de8554f1811f8c9af7f49fff4406e7d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, x_val, y, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c4f51509e3b8356c9876f975bc3fb3ffdfdb6d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100,), (50, 4), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7ae51b8b1743b9a8dd2589b73c5776a9b9521553"
   },
   "outputs": [],
   "source": [
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b476a7001288ceb135e3519d356d8dbf59ef3655"
   },
   "source": [
    "Define validation data as a Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "23dd19e6edfe41cb8792e4a83790ce56782ae170"
   },
   "outputs": [],
   "source": [
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20c466b85734b2033fcf0edde939194f01b2fb62"
   },
   "source": [
    "Put Data through DataLoader, so we can use batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b81492919f53ebe086b2f876730e3e1afb0795da"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x_train)\n",
    "        self.y=torch.from_numpy(y_train)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ebe77da6eb1932f31c883045505a1536c419f2ce"
   },
   "outputs": [],
   "source": [
    "data_set=Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bc17d6857fd1a8f96fbd1075c8818d41eb405c30"
   },
   "outputs": [],
   "source": [
    "trainloader=DataLoader(dataset=data_set,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1f0d283a30bfb529a7e2bec500d6b817eff51b15",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.6000, 3.0000, 6.6000, 2.1000],\n",
       "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
       "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
       "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
       "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
       "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
       "        [5.0000, 2.0000, 3.5000, 1.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "cee4254eabb1081499cdf832052d89133e8adb5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 2, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.y[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1bb20b98a0ff0cdebd02c4179e28e7b66005e00c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4]), torch.Size([100]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x.shape, data_set.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "025acca646b64bde5d3b32eab5b37830adff5d5f"
   },
   "source": [
    "# Build Model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b074f382b8617f92e499c77b149fe012198670f"
   },
   "source": [
    "Build softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "349197f1f133113a3fbc7a1d6b605c27071b7464"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "59c04f9af1d8c4840b6f0597bfe157251cb06134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim=4     # how many Variables are in the dataset\n",
    "hidden_dim = 25 # hidden layers\n",
    "output_dim=3    # number of classes\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "a173404b349fd1973e8d2fcb34fa378b8cef58f9"
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model=Net(input_dim,hidden_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3da6f02923b806ea8e4de21ec746bebd752262fb"
   },
   "source": [
    "View the size of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "83c86946a0dbcc807237546944221ecfa59064c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([25, 4])\n",
      "b torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "print('W:',list(model.parameters())[0].size())\n",
    "print('b',list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a16d78a71884378c33327b1420ca9f752157a91"
   },
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "43d52e9dd8118cfdc21b3f6d67766373c363ccc2"
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfea56a226a09548a6e2ff7766ac9de191ffc30f"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5670f3291a06d37a1ded8a254344087dcd338fd0"
   },
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "89783293ec27e92ba0e9e19ac7a93594cd979918"
   },
   "outputs": [],
   "source": [
    "n_epochs=1000\n",
    "loss_list=[]\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "      \n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss, da Cross Entropy benutzt wird muss ich in den loss Klassen vorhersagen, \n",
    "        # also Wahrscheinlichkeit pro Klasse. Das mach torch.max(y,1)[1])\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "        \n",
    "        \n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "fe6d370fae0553fa66e89a5b3c13b8252bad9ed9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7.9463,   2.9589, -11.4269],\n",
       "        [ -5.9383,   1.7959,   3.4491],\n",
       "        [ -2.0020,   3.1438,  -1.9223],\n",
       "        [ -5.8968,   1.7673,   3.4422],\n",
       "        [  0.4821,   3.8170,  -5.1312],\n",
       "        [ -2.5616,   2.8210,  -1.0162],\n",
       "        [ -2.8092,   2.9822,  -0.9587],\n",
       "        [  6.5563,   3.2080, -10.4113],\n",
       "        [ -1.9753,   3.4324,  -2.2979],\n",
       "        [ -3.5453,   2.6669,   0.1052]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "350d6b55fbcabe933bdae4b755e0e14d57e12262"
   },
   "source": [
    "Each row represents a row from the original dataset. Each column represents a class. The first column represents the class 0, the second column class 1 and the third column class 2. The highest value for each row represents which class the model would put each row. For instance, the highest value in the first row is 9.3748, hence the predicted class is 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c44ec68f380a8d669d318b4d23fce7a6eeb2d3b7"
   },
   "source": [
    "Check model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "8f2d6dbc66c4eedb249811633b0179fd69ef7440"
   },
   "outputs": [],
   "source": [
    "z=model(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "53eb548b75a9237bc4eab0f4e182b669d9015c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.8089, 7.8910, 7.3815, 2.6484, 3.0109, 7.6734, 3.4687, 3.4220, 2.2595,\n",
       "        3.3898, 2.8713, 7.5114, 8.0576, 7.5052, 7.9645, 2.8279, 6.1955, 3.2472,\n",
       "        2.5801, 6.1737, 7.3503, 2.7248, 7.4677, 5.9607, 3.3796, 4.4848, 5.8301,\n",
       "        5.9697, 7.3574, 7.2710, 8.1972, 8.3064, 3.5513, 7.5657, 7.6446, 4.4157,\n",
       "        3.1946, 7.8349, 7.9584, 8.2255, 5.1776, 2.8847, 3.1414, 8.1717, 8.0019,\n",
       "        3.4166, 2.4844, 4.2140, 3.4338, 5.7246]),\n",
       "indices=tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
       "        2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2,\n",
       "        1, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat=torch.max(z.data,1)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "3d83a453a574ce3236ff59364515fbbfe0638911",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
       "        2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2,\n",
       "        1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40c2328d1487fe5f6d122fdbad0a5001e4a9c732"
   },
   "source": [
    "# Original code\n",
    "\n",
    "The full code can be found here: https://github.com/lschmiddey/PyTorch-Multiclass-Classification/blob/master/Softmax_Regression_Deep_Learning_Iris_Dataset.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
